{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aanya/Desktop/old research/vaccine challenge/.venv/lib/python3.13/site-packages/stabl/stabl.py:18: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from stabl.stabl import Stabl, plot_stabl_path, plot_fdr_graph, export_stabl_to_csv, save_stabl_results\n",
    "from stabl.preprocessing import LowInfoFilter\n",
    "from stabl.visualization import boxplot_features, scatterplot_features, plot_roc, boxplot_binary_predictions\n",
    "from stabl.adaptive import ALasso, ALogitLasso\n",
    "from stabl import data\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import Lasso, LogisticRegression, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "%config InlineBackend.figure_formats=['retina'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specimens and data files.\n",
    "data_dir = \"data/\"\n",
    "specimens_file = \"subject_specimen.tsv\"\n",
    "pbmc_cell_freq_file = \"pbmc_cell_frequency.tsv\"\n",
    "pbmc_cell_freq_normalized_file = \"pbmc_cell_frequency_normalized.tsv\"\n",
    "pbmc_gene_expr_file = \"pbmc_gene_expression_raw_count.tsv\"\n",
    "pbmc_gene_expr_raw_file = \"pbmc_gene_expression_raw_count_raw_data.tsv\"\n",
    "plasma_ab_titer_file = \"plasma_ab_titer.tsv\"\n",
    "plasma_ab_titer_normalized_file = \"plasma_ab_titer_normalized.tsv\"\n",
    "plasma_cytokine_file = \"plasma_cytokine_concentrations_by_olink.tsv\"\n",
    "t_cell_act_file = \"t_cell_activation.tsv\"\n",
    "t_cell_pol_file = \"t_cell_polarization.tsv\"\n",
    "th1_th2_pol_file = \"Th1_Th2_polarization_ratio.tsv\"\n",
    "challenge_specimens_file = \"challenge_subject_specimen.tsv\"\n",
    "tranining_specimens_file = \"training_subject_specimen.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load batch corrected data into assay dictionary. Use batch corrected to avoid batch effects. \n",
    "assays = {}\n",
    "assays[\"pbmc_cell_freq\"] = pbmc_cell_freq_file\n",
    "assays[\"pbmc_gene_expr\"] = pbmc_gene_expr_file\n",
    "assays[\"plasma_ab_titer\"] = plasma_ab_titer_file\n",
    "assays[\"plasma_cytokine\"] = plasma_cytokine_file\n",
    "assays[\"t_cell_act\"] = t_cell_act_file\n",
    "assays[\"t_cell_pol\"] = t_cell_pol_file\n",
    "assays[\"th1_th2_pol\"] = th1_th2_pol_file\n",
    "\n",
    "# Use pre batch corrected data for the FC calculations, since batch correction can change the fold change value.\n",
    "assays[\"pbmc_cell_freq_normalized\"] = pbmc_cell_freq_normalized_file\n",
    "assays[\"pbmc_gene_expr_raw\"] = pbmc_gene_expr_raw_file\n",
    "assays[\"plasma_ab_titer_normalized\"] = plasma_ab_titer_normalized_file\n",
    "\n",
    "datasets = [\"2020_dataset\", \"2021_dataset\", \"2022_dataset\", \"2023_dataset\"]\n",
    "training_datasets = [\"2020_dataset\", \"2021_dataset\", \"2022_dataset\"]\n",
    "\n",
    "batch_corrected_assays = [\n",
    "    \"plasma_ab_titer\",\n",
    "    \"plasma_cytokine\",\n",
    "    \"pbmc_gene_expr\",\n",
    "    \"pbmc_cell_freq\",\n",
    "    \"t_cell_act\",\n",
    "    \"t_cell_pol\",\n",
    "    \"th1_th2_pol\",\n",
    "]\n",
    "\n",
    "pre_batch_corrected_assays = [\"pbmc_cell_freq_normalized\", \"pbmc_gene_expr_raw\", \"plasma_ab_titer_normalized\"]\n",
    "\n",
    "# All challenges.\n",
    "challenges = [\n",
    "    \"1.1) IgG-PT-D14-titer-Rank\",\n",
    "    \"1.2) IgG-PT-D14-FC-Rank\",\n",
    "    \"2.1) Monocytes-D1-Rank\",\n",
    "    \"2.2) Monocytes-D1-FC-Rank\",\n",
    "    \"3.1) CCL3-D3-Rank\",\n",
    "    \"3.2) CCL3-D3-FC-Rank\",\n",
    "    \"4.1) IFNG/IL5-Polarization-D30-Rank\",\n",
    "]\n",
    "\n",
    "# Features and assays for each challenge.\n",
    "igg_feature_name = \"IgG_PT\"\n",
    "igg_assay = \"plasma_ab_titer\"\n",
    "\n",
    "monocytes_feature_name = \"Monocytes\"\n",
    "monocytes_assay = \"pbmc_cell_freq\"\n",
    "\n",
    "ccl3_feature_name = \"ENSG00000277632.1\"\n",
    "ccl3_assay = \"pbmc_gene_expr\"\n",
    "\n",
    "bonus_feature_name = \"PT_P01579(IFNÎ³)/PT_P05113(IL5)\"\n",
    "bonus_assay = \"th1_th2_pol\"\n",
    "\n",
    "# Random seed.\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata about all the specimens.\n",
    "specimens = pd.read_table(data_dir + specimens_file)\n",
    "specimens = specimens.set_index(\"specimen_id\")\n",
    "challenge_specimens = pd.read_table(data_dir + challenge_specimens_file).set_index(\"specimen_id\")\n",
    "training_specimens = pd.read_table(data_dir + tranining_specimens_file).set_index(\"specimen_id\")\n",
    "\n",
    "# Get age of each specimen based on year of birth and date of boost.\n",
    "def get_age(row):\n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    birth = datetime.strptime(row[\"year_of_birth\"], date_format)\n",
    "    boost = datetime.strptime(row[\"date_of_boost\"], date_format)\n",
    "    return boost.year - birth.year\n",
    "\n",
    "# Merge age with metadata about specimens.\n",
    "challenge_specimens[\"age\"] = challenge_specimens.apply(get_age, axis=1)\n",
    "training_specimens[\"age\"] = training_specimens.apply(get_age, axis=1)\n",
    "all_specimens_age = pd.concat([challenge_specimens[[\"age\"]], training_specimens[[\"age\"]]])\n",
    "specimens = specimens.merge(all_specimens_age, left_index=True, right_index=True, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all assay data into a dictionary.\n",
    "# Transpose the dataframes so that specimens are rows and features are columns.\n",
    "assay_data = {}\n",
    "for assay, file in assays.items():\n",
    "    df = pd.read_table(data_dir + file)\n",
    "    if assay != bonus_assay:\n",
    "        # The bonus dataset does not require a transpose\n",
    "        df = df.T\n",
    "    else:\n",
    "        df = df.set_index(\"specimen_id\")\n",
    "    df.index = df.index.astype(\"int64\")\n",
    "    df.index.name = \"specimen_id\"\n",
    "    # Remove the dataset column if it exists, as it is not needed for analysis.\n",
    "    if \"dataset\" in df.columns:\n",
    "        df = df.drop(\"dataset\", axis=1)\n",
    "    assay_data[assay] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMEPOINT                  0\n",
      "pbmc_cell_freq                 [20, 33, 21, 48]\n",
      "pbmc_gene_expr                 [36, 36, 21, 53]\n",
      "plasma_ab_titer                [58, 33, 21, 54]\n",
      "plasma_cytokine                [18, 36, 19, 32]\n",
      "t_cell_act                     [0, 34, 20, 52]\n",
      "t_cell_pol                     [0, 27, 16, 51]\n",
      "th1_th2_pol                    [0, 27, 16, 51]\n",
      "Subject count                  [60, 36, 21, 54]\n"
     ]
    }
   ],
   "source": [
    "def print_assay_data_stats(timepoint):\n",
    "    assay_data_stats = {}\n",
    "    print(f\"TIMEPOINT                 \", timepoint)\n",
    "    for assay, data in assay_data.items():\n",
    "        # Only consider batch corrected assays to see distribution of specimens across datasets and timepoints.\n",
    "        if \"_normalized\" in assay or \"_raw\" in assay:\n",
    "            continue\n",
    "        merged_assay_data = data.merge(specimens, left_index=True, right_index=True, how=\"left\")\n",
    "        merged_assay_data = merged_assay_data[merged_assay_data[\"timepoint\"] == timepoint].drop(\"timepoint\", axis=1)\n",
    "        counts = []\n",
    "        for dataset in datasets:\n",
    "            count = len(merged_assay_data[merged_assay_data[\"dataset\"] == dataset])\n",
    "            counts.append(count)\n",
    "        assay_data_stats[assay] = counts\n",
    "\n",
    "    for key, value in assay_data_stats.items():\n",
    "        print(f\"{key:<30}\", value)\n",
    "\n",
    "    subjects = []\n",
    "    # Count number of subjects for each dataset at given timepoint (ignoring assay).\n",
    "    for dataset in datasets:\n",
    "        baseline_specimens = specimens[specimens[\"timepoint\"] == timepoint]\n",
    "        count = len(baseline_specimens[baseline_specimens[\"dataset\"] == dataset])\n",
    "        subjects.append(count)\n",
    "    print(f\"Subject count                 \", subjects)\n",
    "\n",
    "\n",
    "print_assay_data_stats(0)\n",
    "# print_assay_data_stats(-14)\n",
    "# print_assay_data_stats(-15)\n",
    "# print_assay_data_stats(-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_data(individual_assay_data, relevant_assays, relevant_datasets, timepoint):\n",
    "    # Concatenate all relevant assays into a single input dataframe.\n",
    "    input_data = pd.concat(\n",
    "        (lambda d, k: [d[key] for key in k])(individual_assay_data, relevant_assays),\n",
    "        axis=1,\n",
    "    )\n",
    "    input_data = input_data.merge(specimens, left_index=True, right_index=True, how=\"left\")\n",
    "    # Take only relevant datasets.\n",
    "    input_data = input_data[input_data[\"dataset\"].isin(relevant_datasets)]\n",
    "    input_data = input_data.drop(\"date_of_boost\", axis=1)\n",
    "\n",
    "    # Convert infancy_vac and biological_sex to numerical features.\n",
    "    label_encoder = LabelEncoder()\n",
    "    input_data[\"infancy_vac\"] = label_encoder.fit_transform(input_data[\"infancy_vac\"])\n",
    "    input_data[\"biological_sex\"] = label_encoder.fit_transform(input_data[\"biological_sex\"])\n",
    "\n",
    "    # Take only the relevant timepoints.\n",
    "    input_data = input_data[input_data[\"timepoint\"] == timepoint].drop(\"timepoint\", axis=1)\n",
    "    input_data = input_data.set_index(\"subject_id\")\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcomes_dict(individual_assay_data, relevant_datasets):\n",
    "    # Concat all batch corrected assays into a single input dataframe.\n",
    "    input_data = pd.concat(\n",
    "        (lambda d, k: [d[key] for key in k])(individual_assay_data, batch_corrected_assays),\n",
    "        axis=1,\n",
    "    )\n",
    "    input_data = input_data.merge(specimens, left_index=True, right_index=True, how=\"left\")\n",
    "    input_data = input_data[input_data[\"dataset\"].isin(relevant_datasets)].drop(\"dataset\", axis=1)\n",
    "\n",
    "    # Concat all pre batch corrected assays into a single dataframe.\n",
    "    pre_batch_corrected_data = pd.concat(\n",
    "        (lambda d, k: [d[key] for key in k])(individual_assay_data, pre_batch_corrected_assays),\n",
    "        axis=1,\n",
    "    )\n",
    "    pre_batch_corrected_data = pre_batch_corrected_data.merge(specimens, left_index=True, right_index=True, how=\"left\")\n",
    "    pre_batch_corrected_data = pre_batch_corrected_data[\n",
    "        pre_batch_corrected_data[\"dataset\"].isin(relevant_datasets)\n",
    "    ].drop(\"dataset\", axis=1)\n",
    "\n",
    "    # Create batch-corrected data for dataframes for each timepoint.\n",
    "    timepoint_0 = input_data[input_data[\"timepoint\"] == 0].set_index(\"subject_id\")\n",
    "    timepoint_1 = input_data[input_data[\"timepoint\"] == 1].set_index(\"subject_id\")\n",
    "    timepoint_3 = input_data[input_data[\"timepoint\"] == 3].set_index(\"subject_id\")\n",
    "    timepoint_14 = input_data[input_data[\"timepoint\"] == 14].set_index(\"subject_id\")\n",
    "    timepoint_30 = input_data[input_data[\"timepoint\"] == 30].set_index(\"subject_id\")\n",
    "\n",
    "    # Create pre-batch corrected data for each timepoint. \n",
    "    timepoint_0_pre_batch_corrected = pre_batch_corrected_data[pre_batch_corrected_data[\"timepoint\"] == 0].set_index(\n",
    "        \"subject_id\"\n",
    "    )\n",
    "    timepoint_1_pre_batch_corrected = pre_batch_corrected_data[pre_batch_corrected_data[\"timepoint\"] == 1].set_index(\n",
    "        \"subject_id\"\n",
    "    )\n",
    "    timepoint_3_pre_batch_corrected = pre_batch_corrected_data[pre_batch_corrected_data[\"timepoint\"] == 3].set_index(\n",
    "        \"subject_id\"\n",
    "    )\n",
    "    timepoint_14_pre_batch_corrected = pre_batch_corrected_data[pre_batch_corrected_data[\"timepoint\"] == 14].set_index(\n",
    "        \"subject_id\"\n",
    "    )\n",
    "\n",
    "    # Select features for each timepoint and add suffixes to distinguish between timepoints and batch corrected vs pre-batch corrected.\n",
    "    timepoint_0_selected = timepoint_0[[igg_feature_name, monocytes_feature_name, ccl3_feature_name]].add_suffix(\"_0\")\n",
    "    timepoint_0_pre_batch_corrected_selected = timepoint_0_pre_batch_corrected[\n",
    "        [igg_feature_name, monocytes_feature_name, ccl3_feature_name]\n",
    "    ].add_suffix(\"_0P\")\n",
    "    timepoint_1_selected = timepoint_1[[monocytes_feature_name]]\n",
    "    timepoint_1_pre_batch_corrected_selected = timepoint_1_pre_batch_corrected[[monocytes_feature_name]].add_suffix(\n",
    "        \"_P\"\n",
    "    )\n",
    "    timepoint_3_selected = timepoint_3[[ccl3_feature_name]]\n",
    "    timepoint_3_pre_batch_corrected_selected = timepoint_3_pre_batch_corrected[[ccl3_feature_name]].add_suffix(\"_P\")\n",
    "    timepoint_14_selected = timepoint_14[[igg_feature_name]]\n",
    "    timepoint_14_pre_batch_corrected_selected = timepoint_14_pre_batch_corrected[[igg_feature_name]].add_suffix(\"_P\")\n",
    "    timepoint_30_selected = timepoint_30[[bonus_feature_name]]\n",
    "\n",
    "    # Concat all selected feature data into a single dataframe.\n",
    "    all_selected = pd.concat(\n",
    "        [\n",
    "            timepoint_0_selected,\n",
    "            timepoint_0_pre_batch_corrected_selected,\n",
    "            timepoint_1_selected,\n",
    "            timepoint_1_pre_batch_corrected_selected,\n",
    "            timepoint_3_selected,\n",
    "            timepoint_3_pre_batch_corrected_selected,\n",
    "            timepoint_14_selected,\n",
    "            timepoint_14_pre_batch_corrected_selected,\n",
    "            timepoint_30_selected,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Save outcome data using selected feature from each challenge. For FC challenges, calculate fold change using pre-batch corrected data.\n",
    "    outcomes_dict = {}\n",
    "    outcomes_dict[challenges[0]] = all_selected[igg_feature_name]\n",
    "    outcomes_dict[challenges[1]] = all_selected[igg_feature_name + \"_P\"] / all_selected[igg_feature_name + \"_0P\"]\n",
    "    outcomes_dict[challenges[1]].name = igg_feature_name + \"_FC\"\n",
    "\n",
    "    outcomes_dict[challenges[2]] = all_selected[monocytes_feature_name]\n",
    "    outcomes_dict[challenges[3]] = (\n",
    "        all_selected[monocytes_feature_name + \"_P\"] / all_selected[monocytes_feature_name + \"_0P\"]\n",
    "    )\n",
    "    outcomes_dict[challenges[3]].name = monocytes_feature_name + \"_FC\"\n",
    "\n",
    "    outcomes_dict[challenges[4]] = all_selected[ccl3_feature_name]\n",
    "    outcomes_dict[challenges[5]] = all_selected[ccl3_feature_name + \"_P\"] / all_selected[ccl3_feature_name + \"_0P\"]\n",
    "    outcomes_dict[challenges[5]].name = ccl3_feature_name + \"_FC\"\n",
    "\n",
    "    outcomes_dict[challenges[6]] = all_selected[bonus_feature_name]\n",
    "\n",
    "    return outcomes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops filters with percentage of missing values above a threshold.\n",
    "def low_info_filter(df, threshold):\n",
    "    missing_percentages = df.isnull().mean()\n",
    "    return df.loc[:, missing_percentages <= threshold]\n",
    "\n",
    "# Impute missing values using KNN imputer.\n",
    "def impute_missing_values(df):\n",
    "    # Initialize the KNN Imputer with k=3\n",
    "    knn_imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "    # Fit and transform the data\n",
    "    return pd.DataFrame(knn_imputer.fit_transform(df), columns=df.columns, index=df.index)\n",
    "\n",
    "# Normalizes values in dataframe.\n",
    "def scale_values(df):\n",
    "    std_scaler = StandardScaler()\n",
    "    return pd.DataFrame(std_scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
    "\n",
    "# Normalizes values in series.\n",
    "def scale_series(s):\n",
    "    std_scaler = StandardScaler()\n",
    "    data_normalized = std_scaler.fit_transform(s.values.reshape(-1, 1))\n",
    "    return pd.Series(data_normalized.flatten(), index=s.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input subjects:  115\n",
      "Input features:  6779\n",
      "1.1) IgG-PT-D14-titer-Rank Samples : 74 Missing outcomes: 0 Negative outcomes:  1\n",
      "1.2) IgG-PT-D14-FC-Rank Samples : 74 Missing outcomes: 0 Negative outcomes:  0\n",
      "2.1) Monocytes-D1-Rank Samples : 74 Missing outcomes: 0 Negative outcomes:  0\n",
      "2.2) Monocytes-D1-FC-Rank Samples : 74 Missing outcomes: 0 Negative outcomes:  0\n",
      "3.1) CCL3-D3-Rank Samples : 73 Missing outcomes: 0 Negative outcomes:  0\n",
      "3.2) CCL3-D3-FC-Rank Samples : 73 Missing outcomes: 0 Negative outcomes:  0\n",
      "4.1) IFNG/IL5-Polarization-D30-Rank Samples : 46 Missing outcomes: 0 Negative outcomes:  0\n"
     ]
    }
   ],
   "source": [
    "experiment = \"experiment2\"\n",
    "\n",
    "# datasets_to_use = [\"2022_dataset\"]\n",
    "# datasets_to_use = [\"2021_dataset\", \"2022_dataset\"]\n",
    "datasets_to_use = [\"2020_dataset\", \"2021_dataset\", \"2022_dataset\"]\n",
    "\n",
    "# prune_assay = False\n",
    "prune_assay = True\n",
    "\n",
    "input_data = get_input_data(assay_data, batch_corrected_assays, datasets_to_use, timepoint=0)\n",
    "print(\"Input subjects: \", len(input_data))\n",
    "print(\"Input features: \", len(input_data.columns))\n",
    "assert len(input_data.columns.unique()) == len(input_data.columns)\n",
    "\n",
    "outcomes_dict = get_outcomes_dict(assay_data, datasets_to_use)\n",
    "\n",
    "# For each challenge, remove specimens that do not have outcome. \n",
    "def prune_data_without_outcomes(input_data, outcome_data):\n",
    "    assert len(input_data) == len(outcome_data)\n",
    "    pruned_outcome_data = outcome_data[~outcome_data.isna()]\n",
    "    pruned_input_data = input_data[input_data.index.isin(pruned_outcome_data.index)]\n",
    "    assert len(pruned_input_data) == len(pruned_outcome_data)\n",
    "    return pruned_input_data, pruned_outcome_data\n",
    "\n",
    "# Remove specimens that do not have assay data if assay required for that challenge.\n",
    "def prune_data_without_assay(input_data, outcome_data, feature, dataset):\n",
    "    assert len(input_data) == len(outcome_data)\n",
    "    pruned_input_data = input_data[~(input_data[feature].isna() & (input_data[\"dataset\"] == dataset))]\n",
    "    pruned_outcome_data = outcome_data[outcome_data.index.isin(pruned_input_data.index)]\n",
    "    assert len(pruned_input_data) == len(pruned_outcome_data)\n",
    "    return pruned_input_data, pruned_outcome_data\n",
    "\n",
    "# Create training data dictionary with training data for each challenge.\n",
    "training_data_dict = {}\n",
    "for challenge, outcome_data in outcomes_dict.copy().items():\n",
    "    pruned_input_data, pruned_outcome_data = prune_data_without_outcomes(input_data, outcome_data)\n",
    "\n",
    "    # Further prune based on missing assay on a specific dataset.\n",
    "    if prune_assay:\n",
    "        pruned_input_data, pruned_outcome_data = prune_data_without_assay(\n",
    "            pruned_input_data, pruned_outcome_data, monocytes_feature_name, \"2020_dataset\"\n",
    "        )\n",
    "\n",
    "    training_data_dict[challenge] = pruned_input_data.drop(\"dataset\", axis=1)\n",
    "    outcomes_dict[challenge] = pruned_outcome_data\n",
    "\n",
    "for challenge, data in outcomes_dict.items():\n",
    "    print(\n",
    "        challenge,\n",
    "        \"Samples :\",\n",
    "        len(data),\n",
    "        \"Missing outcomes:\",\n",
    "        data.isna().sum(),\n",
    "        \"Negative outcomes: \",\n",
    "        (data < 0).sum().sum(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 10 features for 1.1) IgG-PT-D14-titer-Rank\n",
      "Dropped 10 features for 1.2) IgG-PT-D14-FC-Rank\n",
      "Dropped 10 features for 2.1) Monocytes-D1-Rank\n",
      "Dropped 10 features for 2.2) Monocytes-D1-FC-Rank\n",
      "Dropped 10 features for 3.1) CCL3-D3-Rank\n",
      "Dropped 10 features for 3.2) CCL3-D3-FC-Rank\n",
      "Dropped 0 features for 4.1) IFNG/IL5-Polarization-D30-Rank\n"
     ]
    }
   ],
   "source": [
    "# Drop features with many missing values, impute missing values and scale.\n",
    "def preprocess_training_data(training_data, outcome=\"\", filter_threshold=0.2):\n",
    "    training_data_filtered = low_info_filter(training_data, filter_threshold)\n",
    "    print(\"Dropped\", len(training_data.columns) - len(training_data_filtered.columns), \"features for\", outcome)\n",
    "    # for key in training_data.columns:\n",
    "    #    if key not in training_data_filtered.columns:\n",
    "    #        print(\"Dropped feature \", key)\n",
    "    training_data_imputed = impute_missing_values(training_data_filtered)\n",
    "    training_data_scaled = scale_values(training_data_imputed)\n",
    "    return training_data_scaled\n",
    "\n",
    "\n",
    "for key, value in training_data_dict.copy().items():\n",
    "    training_data_dict[key] = preprocess_training_data(value, key)\n",
    "    \n",
    "    # Scale outcomes\n",
    "    # outcomes_dict[key] = scale_series(outcomes_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1) IgG-PT-D14-titer-Rank\n",
      "['CD4-CD8- T cells', 'CD3-CD19-CD56-CD14-CD16-CD123-CD11c-HLA-DR+cells', 'Intermediate_Monocytes', 'Activated granulocytes', 'ENSG00000184787.18', 'ENSG00000111913.17', 'ENSG00000204356.13', 'ENSG00000096384.19', 'IgG1_PT', 'IgG1_FHA', 'IgG1_OVA', 'IgG1_FIM2/3', 'P80098', 'P04141', 'P05112', 'Q969D9']\n",
      "1.2) IgG-PT-D14-FC-Rank\n",
      "['Proliferating B cells', 'Activated B cells (ABCs)', 'TcmCD8', 'CD4+CD8+ T cells', 'ENSG00000184787.18', 'ENSG00000111913.17', 'ENSG00000204356.13', 'ENSG00000096384.19', 'IgG4_FIM2/3', 'IgG1_PT', 'IgG4_PT', 'IgG3_FIM2/3', 'P09919', 'P14210', 'P80098', 'P13725']\n",
      "2.1) Monocytes-D1-Rank\n",
      "['Proliferating B cells', 'Memory B cells', 'CD3 Tcells', 'NK cells (CD3-CD19-CD56+)', 'ENSG00000165775.17', 'ENSG00000101367.8', 'ENSG00000143753.12', 'ENSG00000135269.17', 'IgG1_PT', 'IgG4_PT', 'IgG3_FIM2/3', 'IgG3_PT', 'Q969D9', 'P04141', 'P05112', 'P01584']\n",
      "2.2) Monocytes-D1-FC-Rank\n",
      "['TcmCD8', 'Non-Classical_Monocytes', 'NaiveCD8', 'cDC1', 'ENSG00000165775.17', 'ENSG00000101367.8', 'ENSG00000143753.12', 'ENSG00000135269.17', 'IgG1_PT', 'IgG3_DT', 'IgG2_TT', 'IgG2_OVA', 'P48061', 'P04141', 'P02778', 'P01584']\n",
      "3.1) CCL3-D3-Rank\n",
      "['Basophils', 'NaiveCD8', 'Proliferating B cells', 'Monocytes', 'ENSG00000184787.18', 'ENSG00000111913.17', 'ENSG00000096384.19', 'ENSG00000204356.13', 'IgG1_PT', 'IgG3_PT', 'IgG4_FIM2/3', 'IgG1_FIM2/3', 'P01375', 'P01584', 'Q96PD4', 'P04141']\n",
      "3.2) CCL3-D3-FC-Rank\n",
      "['TcmCD8', 'NaiveCD8', 'TemraCD8', 'CD4+CD8+ T cells', 'ENSG00000184787.18', 'ENSG00000111913.17', 'ENSG00000096384.19', 'ENSG00000204356.13', 'IgG4_PT', 'IgG1_PT', 'IgG3_PRN', 'IgG4_PRN', 'P35225', 'P04141', 'Q969D9', 'P05112']\n",
      "4.1) IFNG/IL5-Polarization-D30-Rank\n",
      "['TcmCD8', 'CD4+CD8+ T cells', 'Basophils', 'NaiveCD4', 'ENSG00000167261.13', 'ENSG00000176986.15', 'ENSG00000115207.13', 'ENSG00000110442.11', 'IgG1_PT', 'IgG1_OVA', 'IgG3_PRN', 'IgG3_FHA', 'P04141', 'P13232', 'P05112', 'P35225', 'PHA', 'PT', 'TT', 'PT_Q16552', 'PHA_Q16552', 'PHA_P01579', 'PHA_P05113', 'PT_P01579(IFNÎ³)/PT_P05113(IL5)']\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to hold selected features for each challenge.\n",
    "selected_features_dict = {}\n",
    "\n",
    "selected_features_dict[challenges[0]] = ['CD4-CD8- T cells', 'CD3-CD19-CD56-CD14-CD16-CD123-CD11c-HLA-DR+cells', 'Intermediate_Monocytes', 'Activated granulocytes', 'ENSG00000184787.18', 'ENSG00000111913.17', 'ENSG00000204356.13', 'ENSG00000096384.19', 'IgG1_PT', 'IgG1_FHA', 'IgG1_OVA', 'IgG1_FIM2/3', 'P80098', 'P04141', 'P05112', 'Q969D9', 'PHA', 'PT', 'TT', 'PHA_Q16552', 'PHA_P01579', 'PHA_P05113', 'PT_Q16552', 'PT_P01579(IFNÎ³)/PT_P05113(IL5)']\n",
    "\n",
    "\n",
    "selected_features_dict[challenges[1]] = ['Proliferating B cells', 'Activated B cells (ABCs)', 'TcmCD8', 'CD4+CD8+ T cells', 'ENSG00000184787.18', 'ENSG00000111913.17', 'ENSG00000204356.13', 'ENSG00000096384.19', 'IgG4_FIM2/3', 'IgG1_PT', 'IgG4_PT', 'IgG3_FIM2/3', 'P09919', 'P14210', 'P80098', 'P13725', 'PT', 'TT', 'PHA', 'PT_P01579', 'PT_P05113', 'PHA_P05113', 'PHA_P01579', 'PT_P01579(IFNÎ³)/PT_P05113(IL5)']\n",
    "\n",
    "\n",
    "selected_features_dict[challenges[2]] =  ['Proliferating B cells', 'Memory B cells', 'CD3 Tcells', 'NK cells (CD3-CD19-CD56+)', 'ENSG00000165775.17', 'ENSG00000101367.8', 'ENSG00000143753.12', 'ENSG00000135269.17', 'IgG1_PT', 'IgG4_PT', 'IgG3_FIM2/3', 'IgG3_PT', 'Q969D9', 'P04141', 'P05112', 'P01584', 'PHA', 'TT', 'PT', 'PT_P01579', 'PT_Q16552', 'PT_P05113', 'PHA_Q16552', 'PT_P01579(IFNÎ³)/PT_P05113(IL5)']\n",
    "\n",
    "selected_features_dict[challenges[3]] =  ['TcmCD8', 'Non-Classical_Monocytes', 'NaiveCD8', 'cDC1', 'ENSG00000165775.17', 'ENSG00000101367.8', 'ENSG00000143753.12', 'ENSG00000135269.17', 'IgG1_PT', 'IgG3_DT', 'IgG2_TT', 'IgG2_OVA', 'P48061', 'P04141', 'P02778', 'P01584', 'PT', 'PHA', 'TT', 'PHA_P05113', 'PT_P05113', 'PT_P01579', 'PHA_P01579', 'PT_P01579(IFNÎ³)/PT_P05113(IL5)']\n",
    "\n",
    "selected_features_dict[challenges[4]] =  ['Basophils', 'NaiveCD8', 'Proliferating B cells', 'Monocytes', 'ENSG00000184787.18', 'ENSG00000111913.17', 'ENSG00000096384.19', 'ENSG00000204356.13', 'IgG1_PT', 'IgG3_PT', 'IgG4_FIM2/3', 'IgG1_FIM2/3', 'P01375', 'P01584', 'Q96PD4', 'P04141', 'TT', 'PT', 'PHA', 'PHA_P05113', 'PT_P05113', 'PT_P01579', 'PT_Q16552', 'PT_P01579(IFNÎ³)/PT_P05113(IL5)']\n",
    "\n",
    "selected_features_dict[challenges[5]] =  ['TcmCD8', 'NaiveCD8', 'TemraCD8', 'CD4+CD8+ T cells', 'ENSG00000184787.18', 'ENSG00000111913.17', 'ENSG00000096384.19', 'ENSG00000204356.13', 'IgG4_PT', 'IgG1_PT', 'IgG3_PRN', 'IgG4_PRN', 'P35225', 'P04141', 'Q969D9', 'P05112', 'PHA', 'PT', 'TT', 'PHA_P05113', 'PT_P05113', 'PT_Q16552', 'PHA_Q16552', 'PT_P01579(IFNÎ³)/PT_P05113(IL5)']\n",
    "\n",
    "selected_features_dict[challenges[6]] =  ['TcmCD8', 'CD4+CD8+ T cells', 'Basophils', 'NaiveCD4', 'ENSG00000167261.13', 'ENSG00000176986.15', 'ENSG00000115207.13', 'ENSG00000110442.11', 'IgG1_PT', 'IgG1_OVA', 'IgG3_PRN', 'IgG3_FHA', 'P04141', 'P13232', 'P05112', 'P35225', 'PHA', 'PT', 'TT', 'PT_Q16552', 'PHA_Q16552', 'PHA_P01579', 'PHA_P05113', 'PT_P01579(IFNÎ³)/PT_P05113(IL5)']\n",
    "\n",
    "\n",
    "# For each challenge, find relevant training data and prune features based on selected features.\n",
    "relevant_training_data_dict = {}\n",
    "pruned_features_dict = {}\n",
    "for challenge, selected_features in selected_features_dict.items():\n",
    "    print(challenge)\n",
    "    data = training_data_dict[challenge]\n",
    "    pruned_features = []\n",
    "    # Check if the selected features are in the data columns.\n",
    "    for feature in selected_features:\n",
    "        if feature in data.columns:\n",
    "            pruned_features.append(feature)\n",
    "    print(pruned_features)\n",
    "    relevant_training_data_dict[challenge] = data[pruned_features]\n",
    "    pruned_features_dict[challenge] = pruned_features\n",
    "    assert(len(relevant_training_data_dict[challenge].columns) == len(pruned_features))\n",
    "selected_features_dict = pruned_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"experiment-mofa\"\n",
    "\n",
    "def spearman_correlation(y_true, y_pred):\n",
    "    # Calculate Spearman correlation\n",
    "    if np.std(y_pred) == 0:\n",
    "        return -1\n",
    "    rho, _ = spearmanr(y_true, y_pred)\n",
    "    return rho  # Higher is better\n",
    "\n",
    "\n",
    "# Convert it into a scikit-learn scorer\n",
    "spearman_scorer = make_scorer(spearman_correlation, greater_is_better=True)\n",
    "\n",
    "# Create ElasticNet model and perform grid search for hyperparameter tuning.\n",
    "best_model_accuracy_dict = {}\n",
    "best_model_dict = {}\n",
    "best_model_features_dict = {}\n",
    "for challenge in challenges:\n",
    "    # Create a grid search for hyperparameter tuning of ElasticNet model.\n",
    "    model = ElasticNet(max_iter=int(1e7), random_state=random_state)\n",
    "    param_grid = {\"alpha\": [0.001, 0.005, 0.01, 0.05, 0.1, 0.5], \"l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9]}\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring=spearman_scorer)\n",
    "\n",
    "    grid_search.fit(relevant_training_data_dict[challenge], outcomes_dict[challenge])\n",
    "\n",
    "    best_param = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(challenge, \"Best Parameter (C):\", best_param, \"Cross-Validated Score:\", best_score)\n",
    "\n",
    "    best_model = ElasticNet(\n",
    "        best_param[\"alpha\"], l1_ratio=best_param[\"l1_ratio\"], max_iter=int(1e6), random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Perform cross-validation to inspect best model's performance.\n",
    "    scores = cross_val_score(\n",
    "        best_model, relevant_training_data_dict[challenge], outcomes_dict[challenge], scoring=spearman_scorer, cv=5\n",
    "    )\n",
    "\n",
    "    # Print scores for each fold and the mean score\n",
    "    print(\"Cross-Validation Scores:\", scores)\n",
    "    print(\"Mean Cross-Validation Score:\", scores.mean())\n",
    "\n",
    "    model = ElasticNet(\n",
    "        alpha=best_param[\"alpha\"], l1_ratio=best_param[\"l1_ratio\"], max_iter=int(1e7), random_state=random_state\n",
    "    )\n",
    "    model.fit(relevant_training_data_dict[challenge], outcomes_dict[challenge])\n",
    "    accuracy = model.score(relevant_training_data_dict[challenge], outcomes_dict[challenge])\n",
    "    print(\"MODEL ACCURACY:\", accuracy)\n",
    "    y_pred = model.predict(relevant_training_data_dict[challenge])\n",
    "    spearmanc = spearman_correlation(outcomes_dict[challenge], y_pred)\n",
    "    print(\"SPEARMAN CORRELATION: \", spearmanc)\n",
    "    print(model.coef_)\n",
    "\n",
    "    best_model_accuracy_dict[challenge] = spearmanc\n",
    "    best_model_dict[challenge] = model\n",
    "    assert len(model.feature_names_in_) == len(model.coef_)\n",
    "    # Create a list of feature and their weights in the model for each challenge.\n",
    "    features_weight_list = []\n",
    "    for i in range(0, len(model.coef_)):\n",
    "        features_weight_list.append((model.feature_names_in_[i], model.coef_[i]))\n",
    "    assert len(features_weight_list) == len(model.coef_)\n",
    "    sorted_features_weight_list = sorted(features_weight_list, key=lambda x: abs(x[1]), reverse=True)\n",
    "    best_model_features_dict[challenge] = sorted_features_weight_list\n",
    "\n",
    "# Print best model accuracy for each challenge.\n",
    "for key, value in best_model_accuracy_dict.items():\n",
    "    print(key, value)\n",
    "\n",
    "# Save the results of the experiment.\n",
    "with open(experiment + \".modelinfo\", \"w\") as file:\n",
    "    file.write(str(datasets_to_use) + \"\\n\")\n",
    "    file.write(\"Prune assay \" + str(prune_assay) + \"\\n\")\n",
    "    for key, value in best_model_accuracy_dict.items():\n",
    "        file.write(key + \" \" + str(value) + \"\\n\")\n",
    "\n",
    "for key, value in best_model_features_dict.items():\n",
    "    with open(experiment + \"-\" + key[:3], \"w\") as file:\n",
    "        for feature in value:\n",
    "            file.write(feature[0] + \" \" + str(feature[1]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input subjects:  54\n",
      "Input features:  6778\n",
      "Dropped 0 features for all\n"
     ]
    }
   ],
   "source": [
    "# Use best model to make predictions on the challenge dataset.\n",
    "\n",
    "# Load challenge dataset. \n",
    "challenge_dataset = [\"2023_dataset\"]\n",
    "challenge_data = get_input_data(assay_data, batch_corrected_assays, challenge_dataset, timepoint=0).drop(\n",
    "    \"dataset\", axis=1\n",
    ")\n",
    "\n",
    "# Get number of subjects and features in the challenge dataset.\n",
    "print(\"Input subjects: \", len(challenge_data))\n",
    "print(\"Input features: \", len(challenge_data.columns))\n",
    "assert len(challenge_data.columns.unique()) == len(challenge_data.columns)\n",
    "\n",
    "predictions_dict = {}\n",
    "ranks_dict = {}\n",
    "\n",
    "# Preprocess the challenge data.\n",
    "challenge_data = preprocess_training_data(challenge_data, outcome=\"all\", filter_threshold=1).sort_index()\n",
    "\n",
    "# For each challenge, make predictions using the best model and calculate ranks.\n",
    "for challenge, model in best_model_dict.items():\n",
    "    predictions_dict[challenge] = pd.Series(\n",
    "        model.predict(challenge_data.loc[:, selected_features_dict[challenge]]), index=challenge_data.index\n",
    "    )\n",
    "    ranks_dict[challenge] = predictions_dict[challenge].rank(method=\"first\", ascending=False).astype(int)\n",
    "    ranks_dict[challenge].name = challenge\n",
    "\n",
    "\n",
    "# Create a final dataframe with all predictions and ranks for the challenge dataset.\n",
    "final = pd.concat(ranks_dict.values(), axis=1)\n",
    "\n",
    "# Merge with subjects to get subject information in final dataframe.\n",
    "subjects = specimens[specimens[\"dataset\"] == challenge_dataset[0]].drop(\"dataset\", axis=1)\n",
    "subjects = subjects[subjects[\"timepoint\"] == 0].drop(\"timepoint\", axis=1).set_index(\"subject_id\")\n",
    "final = subjects.merge(final, left_index=True, right_index=True, how=\"right\").drop(\"date_of_boost\", axis=1)\n",
    "assert len(final) == 54\n",
    "final.index.name = \"SubjectID\"\n",
    "final = final.rename(\n",
    "    columns={\"infancy_vac\": \"VaccinePrimingStatus\", \"age\": \"Age\", \"biological_sex\": \"BiologicalSexAtBirth\"}\n",
    ")\n",
    "ordered_columns = [\"Age\",\"BiologicalSexAtBirth\",\"VaccinePrimingStatus\"]\n",
    "ordered_columns += challenges\n",
    "final = final[ordered_columns]\n",
    "\n",
    "# Save final rank results to a TSV file.\n",
    "final.to_csv(experiment + \".tsv\", sep=\"\\t\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
